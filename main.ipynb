{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# read all the file names in the folder named CNV and store them in a list\n",
    "import glob\n",
    "cnv = glob.glob(\"CNV/*.jpeg\")\n",
    "dme = glob.glob(\"DME/*.jpeg\")\n",
    "drusen = glob.glob(\"DRUSEN/*.jpeg\")\n",
    "normal = glob.glob(\"NORMAL/*.jpeg\")\n",
    "\n",
    "# get only top 1000 images from each category\n",
    "cnv = cnv[:1000]\n",
    "dme = dme[:1000]\n",
    "drusen = drusen[:1000]\n",
    "normal = normal[:1000]\n",
    "\n",
    "\n",
    "# read all the images and store them in a list\n",
    "cnv_images = [cv2.imread(img) for img in cnv]\n",
    "# print(\"Read all the images from CNV folder\")\n",
    "dme_images = [cv2.imread(img) for img in dme]\n",
    "# print(\"Read all the images from DME folder\")\n",
    "drusen_images = [cv2.imread(img) for img in drusen]\n",
    "# print(\"Read all the images from DRUSEN folder\")\n",
    "normal_images = [cv2.imread(img) for img in normal]\n",
    "# print(\"Read all the images from NORMAL folder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "def preProcess(img):\n",
    "    # use matplotlib to plot the first image from cnv_images\n",
    "    from PIL import Image\n",
    "    import matplotlib.pyplot as plt\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # applymedian filter to the image\n",
    "    import numpy as np\n",
    "    median = cv2.medianBlur(img, 5)\n",
    "    # plt.imshow(median)\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    # ehnance the image using another library\n",
    "    from PIL import ImageEnhance\n",
    "    enhancer = ImageEnhance.Contrast(Image.fromarray(median))\n",
    "    enhanced_im = enhancer.enhance(2.0)\n",
    "    # plt.imshow(enhanced_im)\n",
    "    # plt.show()\n",
    "\n",
    "    # apply thresholding to the enhanced image\n",
    "    \n",
    "    ret,thresh1 = cv2.threshold(np.array(enhanced_im), 50, 255, cv2.THRESH_BINARY)\n",
    "    # plt.imshow(thresh1)\n",
    "    # plt.show()\n",
    "\n",
    "    # set the pixels of cnv_images[0] to 0 where thresh1 is 0\n",
    "    img[thresh1==0] = 0\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    # crop img 100 from top\n",
    "    img = img[50:,:]\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    # crop img 100 from bottom\n",
    "    img = img[:-50,:]\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    # resize the image to 256x256\n",
    "    img = cv2.resize(img, (256,256))\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    # apply cannny edge detection\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    # plt.imshow(edges)\n",
    "    # plt.show()\n",
    "    # color the edges red in the img\n",
    "    img[edges>0] = (255,0,0)\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # apply the preProcess function to all the images in the cnv_images list, dme_images list, drusen_images list and normal_images list\n",
    "# cnv_images = [preProcess(img) for img in cnv_images]\n",
    "# dme_images = [preProcess(img) for img in dme_images]\n",
    "# drusen_images = [preProcess(img) for img in drusen_images]\n",
    "# normal_images = [preProcess(img) for img in normal_images]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a labels list with 0 for cnv, 1 for dme, 2 for drusen and 3 for normal \n",
    "labelsMap = {\"CNV\":0, \"DME\":1, \"DRUSEN\":2, \"NORMAL\":3}\n",
    "\n",
    "# create a dataframes list with all the images and labels in another column\n",
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "df[\"images\"] = cnv_images + dme_images + drusen_images + normal_images\n",
    "df[\"labels\"] = [labelsMap[\"CNV\"]]*len(cnv_images) + [labelsMap[\"DME\"]]*len(dme_images) + [labelsMap[\"DRUSEN\"]]*len(drusen_images) + [labelsMap[\"NORMAL\"]]*len(normal_images)\n",
    "\n",
    "# shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - 583s 6s/step - loss: 2.2113 - accuracy: 0.4328 - val_loss: 2.3697 - val_accuracy: 0.3125\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 594s 6s/step - loss: 0.9784 - accuracy: 0.7116 - val_loss: 2.1237 - val_accuracy: 0.4938\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 573s 6s/step - loss: 0.4616 - accuracy: 0.8462 - val_loss: 1.6200 - val_accuracy: 0.6325\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 547s 5s/step - loss: 0.2027 - accuracy: 0.9262 - val_loss: 1.7371 - val_accuracy: 0.5938\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 592s 6s/step - loss: 0.1549 - accuracy: 0.9409 - val_loss: 1.8243 - val_accuracy: 0.5925\n",
      "1/1 [==============================] - 0s 281ms/step\n",
      "[2 0 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "# create a cnn model for classification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"images\"], df[\"labels\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# convert the images into numpy array\n",
    "X_train = np.array(X_train.tolist())\n",
    "X_test = np.array(X_test.tolist())\n",
    "\n",
    "# reshape the data to 4 dimensions\n",
    "X_train = X_train.reshape(X_train.shape[0], 256, 256, 3)\n",
    "X_test = X_test.reshape(X_test.shape[0], 256, 256, 3)\n",
    "\n",
    "# convert the labels into categorical format\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# create a sequential model\n",
    "model = Sequential()\n",
    "# add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(256,256,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Conv2D(8, kernel_size=3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)\n",
    "\n",
    "# save the model to disk as eyemodel.h5\n",
    "model.save(\"eyemodel.h5\")\n",
    "\n",
    "# create a model 2 with learning rate 0.0001\n",
    "model2 = Sequential()\n",
    "# add model layers\n",
    "model2.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(256,256,3)))\n",
    "# set learning rate to 0.001\n",
    "lr = 0.0001\n",
    "model2.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Conv2D(16, kernel_size=3, activation=\"relu\"))\n",
    "model2.add(Conv2D(8, kernel_size=3, activation=\"relu\"))\n",
    "\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "# compile the model\n",
    "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 26s 1s/step\n",
      "0.5925\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'labelsMap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18820/4095043860.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"CNV-53018-1.jpeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;31m# save model as .sav file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18820/4095043860.py\u001b[0m in \u001b[0;36mpredictImage\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# return prediction from labelsMap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelsMap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabelsMap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# print the prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labelsMap' is not defined"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "testmodel = load_model(\"eyeModel2.h5\")\n",
    "# print accuracy of the model\n",
    "# print(\"Accuracy of the model is - \" , testmodel.evaluate(X_test, y_test)[1]*100 , \"%\")\n",
    "\n",
    "def predictImage(img):\n",
    "    \n",
    "\n",
    "    # preprocess the image\n",
    "    img = preProcess(img)\n",
    "\n",
    "    # convert the image into numpy array\n",
    "    img = np.array(img.tolist())\n",
    "\n",
    "    # reshape the image\n",
    "    img = img.reshape(1, 256, 256, 3)\n",
    "\n",
    "    # predict the image\n",
    "    prediction = testmodel.predict(img)\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "    # return prediction from labelsMap\n",
    "    return list(labelsMap.keys())[list(labelsMap.values()).index(prediction[0])]\n",
    "\n",
    "    # print the prediction\n",
    "    print(np.argmax(prediction, axis=1))\n",
    "\n",
    "img = cv2.imread(\"CNV-53018-1.jpeg\")\n",
    "print(predictImage(img))\n",
    "\n",
    "# save model as .sav file\n",
    "import pickle\n",
    "pickle.dump(testmodel, open(\"eyeModel.sav\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6581c89-cb13-4066-93b2-4a96fdd4a402/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://e6581c89-cb13-4066-93b2-4a96fdd4a402/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eyeModel.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmodel = load_model(\"eyeModel2.h5\")\n",
    "\n",
    "# user joblib to save model as .pkl file\n",
    "import joblib\n",
    "joblib.dump(testmodel, \"eyeModel.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://429a46b2-7de0-4b44-b9f6-fec6dbffb868/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18820/2428356098.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load the model .pkl file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtestmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"eyeModel.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# img = cv2.imread(\"CNV-53018-1.jpeg\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mload_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 587\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    588\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m             warnings.warn(\"The file '%s' has been generated with a \"\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                 \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\pickle.py\u001b[0m in \u001b[0;36mload_reduce\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1588\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1589\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1590\u001b[1;33m         \u001b[0mstack\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1591\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\saving\\pickle_utils.py\u001b[0m in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m           \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LENOVO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    913\u001b[0m                         ckpt_options, options, filters)\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         raise FileNotFoundError(\n\u001b[0m\u001b[0;32m    916\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n You may be trying to load on a different device \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;34m\"from the computational device. Consider setting the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://429a46b2-7de0-4b44-b9f6-fec6dbffb868/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "\n",
    "# load the model .pkl file\n",
    "import joblib\n",
    "testmodel = joblib.load(\"eyeModel.pkl\")\n",
    "\n",
    "# img = cv2.imread(\"CNV-53018-1.jpeg\")\n",
    "# img = preProcess(img)\n",
    "\n",
    "#     # convert the image into numpy array\n",
    "# img = np.array(img.tolist())\n",
    "\n",
    "#     # reshape the image\n",
    "# img = img.reshape(1, 256, 256, 3)\n",
    "\n",
    "#     # predict the image\n",
    "# prediction = testmodel.predict(img)\n",
    "# prediction = np.argmax(prediction, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
